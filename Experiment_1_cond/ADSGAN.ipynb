{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q4t0avdQCPZL"
      },
      "outputs": [],
      "source": [
        "!pip install git+https://github.com/Ashhad785/synthcity.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CEODMo6FCSqm"
      },
      "outputs": [],
      "source": [
        "!pip uninstall -y torchaudio torchdata\n",
        "!pip install pycox\n",
        "from pycox import datasets\n",
        "from synthcity.metrics import Metrics\n",
        "from synthcity.plugins.core.dataloader import SurvivalAnalysisDataLoader\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import shutil\n",
        "from timeit import default_timer as timer\n",
        "from synthcity.plugins import Plugins"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EHCownpHdrh1"
      },
      "outputs": [],
      "source": [
        "plugin_name=\"adsgan\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g66l69NIdwo0"
      },
      "source": [
        "# Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iw4DqUnXCjNr"
      },
      "outputs": [],
      "source": [
        "from scipy.stats import gaussian_kde\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from timeit import default_timer as timer\n",
        "from sklearn.mixture import BayesianGaussianMixture\n",
        "\n",
        "\n",
        "def fit_dpmm_and_sample(data, sample_size, integer_sampling=False, bandwidth='scott'):\n",
        "   \"\"\"\n",
        "   Fit DPMM to data and sample from it\n",
        "   Parameters:\n",
        "   -----------\n",
        "   data : array-like\n",
        "       Input data to fit DPMM\n",
        "   sample_size : int\n",
        "       Number of samples to generate\n",
        "   integer_sampling : bool, default=False\n",
        "       If True, returns integer samples. If False, returns continuous samples\n",
        "   bandwidth : str or float, default='scott'\n",
        "       Not used for DPMM but kept for API consistency\n",
        "   Returns:\n",
        "   --------\n",
        "   array-like\n",
        "       Sampled values from the fitted DPMM\n",
        "   \"\"\"\n",
        "   # Reshape data for DPMM\n",
        "   data = data.reshape(-1, 1)\n",
        "\n",
        "   # Fit DPMM\n",
        "   dpmm = BayesianGaussianMixture(\n",
        "       n_components=10,  # Max number of components\n",
        "       weight_concentration_prior=1.0,\n",
        "       random_state=42\n",
        "   )\n",
        "   dpmm.fit(data)\n",
        "\n",
        "   if integer_sampling:\n",
        "       # Sample more points than needed to account for rounding and filtering\n",
        "       oversampling_factor = 1.5\n",
        "       samples = dpmm.sample(int(sample_size * oversampling_factor))[0].reshape(-1)\n",
        "       # Round to nearest integer and ensure positive\n",
        "       samples = np.round(np.abs(samples))\n",
        "       # Convert to integers\n",
        "       samples = samples.astype(int)\n",
        "       # Remove any zeros\n",
        "       samples = samples[samples > 0]\n",
        "       # If we have more samples than needed due to oversampling, randomly select\n",
        "       if len(samples) > sample_size:\n",
        "           samples = np.random.choice(samples, size=sample_size, replace=False)\n",
        "       # If we have fewer samples than needed, resample with replacement\n",
        "       elif len(samples) < sample_size:\n",
        "           samples = np.random.choice(samples, size=sample_size, replace=True)\n",
        "   else:\n",
        "       # Direct sampling for continuous values\n",
        "       samples = dpmm.sample(sample_size)[0].reshape(-1)\n",
        "       # Ensure all samples are positive\n",
        "       samples = np.abs(samples)\n",
        "\n",
        "   return samples\n",
        "\n",
        "\n",
        "def sinusoidal_embedding(values, event_indicators, embedding_dim):\n",
        "    # Find the unique values and sort them\n",
        "    unique_values = sorted(set(values))\n",
        "\n",
        "    # Create a dictionary to map values to their indices\n",
        "    value_to_idx = {value: idx for idx, value in enumerate(unique_values)}\n",
        "\n",
        "    # Create the embedding matrix\n",
        "    embeddings = np.zeros((len(unique_values), embedding_dim + 1))\n",
        "\n",
        "    # Assign sinusoidal embeddings based on the order of values\n",
        "    for idx, value in enumerate(unique_values):\n",
        "        for j in range(embedding_dim // 2):\n",
        "            embeddings[idx, 2 * j] = np.sin(idx / (10000 ** (2 * j / embedding_dim)))\n",
        "            embeddings[idx, 2 * j + 1] = np.cos(idx / (10000 ** (2 * j / embedding_dim)))\n",
        "\n",
        "    # Map the input values to their embeddings\n",
        "    value_embeddings = []\n",
        "    for value, event_indicator in zip(values, event_indicators):\n",
        "        embedding = embeddings[value_to_idx[value]].copy()\n",
        "        embedding[-1] = event_indicator\n",
        "        value_embeddings.append(embedding)\n",
        "\n",
        "    return np.array(value_embeddings)\n",
        "\n",
        "\n",
        "from scipy.stats import mannwhitneyu, chi2_contingency,wilcoxon\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def identify_variable_types(df):\n",
        "    continuous_columns = []\n",
        "    discrete_columns = []\n",
        "\n",
        "    for col in df.columns:\n",
        "        unique_vals = df[col].unique()\n",
        "        num_unique = len(unique_vals)\n",
        "        if num_unique > 20:  # Threshold for considering a column as continuous\n",
        "            continuous_columns.append(col)\n",
        "        else:\n",
        "            discrete_columns.append(col)\n",
        "\n",
        "    return continuous_columns, discrete_columns\n",
        "\n",
        "def compare_distributions(real_df, synthetic_df, alpha=0.05):\n",
        "    real_df = real_df.drop(['duration', 'event'], axis=1)\n",
        "    real_continuous, real_discrete = identify_variable_types(real_df)\n",
        "    p_values_continuous = {}\n",
        "    p_values_discrete = {}\n",
        "\n",
        "    synthetic_df = synthetic_df.drop(['duration', 'event'], axis=1)\n",
        "    synthetic_continuous, synthetic_discrete = identify_variable_types(synthetic_df)\n",
        "\n",
        "    synthetic_continuous = [col for col in synthetic_continuous if col not in [\"event\", \"duration\"]]\n",
        "    synthetic_discrete = [col for col in synthetic_discrete if col not in [\"event\", \"duration\"]]\n",
        "\n",
        "    # Wilcoxon rank-sum test for continuous variables\n",
        "    for col in real_continuous:\n",
        "        if col in synthetic_continuous:\n",
        "            _, p_value = mannwhitneyu(real_df[col], synthetic_df[col])\n",
        "            p_values_continuous[col] = p_value\n",
        "\n",
        "    # Chi-square test for discrete variables\n",
        "    for col in real_discrete:\n",
        "        if col in synthetic_discrete:\n",
        "            contingency_table = pd.crosstab(real_df[col], synthetic_df[col])\n",
        "            _, p, _, _ = chi2_contingency(contingency_table)\n",
        "            p_values_discrete[col] = p\n",
        "\n",
        "    # Plot p-values\n",
        "    # plt.figure(figsize=(10, 6))\n",
        "\n",
        "    # continuous_p_values = {col: p_values_continuous[col] for col in real_continuous}\n",
        "    # discrete_p_values = {col: p_values_discrete[col] for col in real_discrete}\n",
        "\n",
        "    # plt.plot(list(continuous_p_values.keys()), list(continuous_p_values.values()), label='Continuous', marker='o')\n",
        "    # plt.plot(list(discrete_p_values.keys()), list(discrete_p_values.values()), label='Discrete', marker='o', linestyle='dashed')\n",
        "\n",
        "    # # Plot alpha line\n",
        "    # plt.axhline(y=alpha, color='red', linestyle='--', label=f'alpha = {alpha}')\n",
        "\n",
        "    # plt.xlabel('Column Name')\n",
        "    # plt.ylabel('p-value')\n",
        "    # plt.title('Comparison of p-values for Real and Synthetic Data')\n",
        "    # plt.xticks(rotation=45)\n",
        "    # plt.legend()\n",
        "    # plt.grid(True)\n",
        "    # plt.tight_layout()\n",
        "    # plt.show()\n",
        "\n",
        "    return p_values_continuous, p_values_discrete\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# FLCHAIN"
      ],
      "metadata": {
        "id": "lP35B_XTL2bL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset=\"flchain\"\n",
        "\n",
        "metrics_list = []\n",
        "fit_times = []\n",
        "generate_times = []\n",
        "p_values_list = []\n",
        "\n",
        "for i in range(5):\n",
        "    df = pd.read_csv('/content/drive/MyDrive/Datasets/flchain_final.csv')\n",
        "    df = df.drop('Unnamed: 0', axis=1)\n",
        "    df = df[df['duration'] != 0]\n",
        "\n",
        "    time = df['duration'].to_list()\n",
        "    event = df['event'].to_list()\n",
        "\n",
        "    time_event_encoded = sinusoidal_embedding(time, event, 4)\n",
        "    X = df.drop(['duration', 'event'], axis=1)\n",
        "    y = time_event_encoded\n",
        "\n",
        "    syn_model = Plugins().get(plugin_name)\n",
        "\n",
        "    # Measure the execution time of the fit function\n",
        "    start = timer()\n",
        "    syn_model.fit(X, cond=y)\n",
        "    fit_time = timer() - start\n",
        "    fit_times.append(fit_time)\n",
        "\n",
        "    survival_df=df\n",
        "    event_0_data = survival_df[survival_df['event'] == 0]['duration'].values\n",
        "    event_1_data = survival_df[survival_df['event'] == 1]['duration'].values\n",
        "\n",
        "    random_state = i + 1\n",
        "    np.random.seed(random_state)\n",
        "\n",
        "    # Use KDE to sample time values for each event type\n",
        "    sample_size_0 = len(event_0_data)\n",
        "    sample_size_1 = len(event_1_data)\n",
        "\n",
        "    # Sample from KDE for each event type\n",
        "    sample_event_0 = fit_dpmm_and_sample(event_0_data, sample_size_0,integer_sampling=True)\n",
        "    sample_event_1 = fit_dpmm_and_sample(event_1_data, sample_size_1,integer_sampling=True)\n",
        "\n",
        "    z=np.concatenate([sample_event_0,sample_event_1])\n",
        "    x=np.zeros(len(sample_event_0))\n",
        "    y=np.ones(len(sample_event_1))\n",
        "    p=np.concatenate([x,y])\n",
        "\n",
        "    time_event_gen_encoded=sinusoidal_embedding(z,p,4)\n",
        "\n",
        "    # Measure the execution time of the generate function\n",
        "    start = timer()\n",
        "    X_gen = syn_model.generate(count=len(df), cond=np.array(time_event_gen_encoded)).dataframe()\n",
        "    generate_time = timer() - start\n",
        "    generate_times.append(generate_time)\n",
        "\n",
        "    X_gen['duration'] = z\n",
        "    X_gen['event'] = p\n",
        "    X_gen = X_gen.sample(frac=1).reset_index(drop=True)\n",
        "\n",
        "    # Save X_gen as a CSV file\n",
        "    X_gen.to_csv(f\"/content/drive/MyDrive/ICML/{dataset}_{plugin_name}_iteration_{i+1}.csv\", index=False)\n",
        "\n",
        "    loader1 = SurvivalAnalysisDataLoader(df, target_column=\"event\", time_to_event_column=\"duration\")\n",
        "    loader2 = SurvivalAnalysisDataLoader(X_gen, target_column=\"event\", time_to_event_column=\"duration\")\n",
        "\n",
        "    met_df = Metrics.evaluate(X_gt=loader1, X_syn=loader2, task_type='survival_analysis', metrics={\n",
        "        'stats': ['jensenshannon_dist', 'chi_squared_test', 'feature_corr', 'inv_kl_divergence', 'ks_test',\n",
        "                 'max_mean_discrepancy', 'wasserstein_dist', 'prdc', 'alpha_precision', 'survival_km_distance'],\n",
        "        'performance': ['linear_model', 'mlp', 'xgb', 'feat_rank_distance']\n",
        "    }, use_cache=False, random_state=random_state)\n",
        "\n",
        "    met_df = met_df.iloc[:, 0]\n",
        "    metrics_list.append(met_df)\n",
        "\n",
        "    # Calculate p-values\n",
        "    p_values_continuous, p_values_discrete = compare_distributions(df, X_gen)\n",
        "    continuous_column_names = list(p_values_continuous.keys())\n",
        "    discrete_column_names = list(p_values_discrete.keys())\n",
        "\n",
        "    p_val = np.concatenate([list(p_values_continuous.values()), list(p_values_discrete.values())])\n",
        "    p_values_list.append(p_val)\n",
        "\n",
        "    workspace_dir = os.path.join(os.getcwd(), 'workspace')\n",
        "    if os.path.exists(workspace_dir):\n",
        "        shutil.rmtree(workspace_dir)\n",
        "\n",
        "result_df = pd.concat(metrics_list, axis=1)\n",
        "\n",
        "# Calculate the row-wise mean and standard deviation of the metrics\n",
        "result_df['Mean'] = result_df.mean(axis=1)\n",
        "result_df['Std'] = result_df.std(axis=1)\n",
        "result_df['Std'] = result_df['Std'].round(4)\n",
        "\n",
        "# Create DataFrame for p-values\n",
        "p_values_df = pd.DataFrame(p_values_list, columns=continuous_column_names + discrete_column_names)\n",
        "\n",
        "# Save result_df and p_values_df as CSV files\n",
        "result_df.to_csv(f\"/content/drive/MyDrive/ICML/{dataset}_{plugin_name}_result_df.csv\")\n",
        "p_values_df.to_csv(f\"/content/drive/MyDrive/ICML/{dataset}_{plugin_name}_p_values_df.csv\")\n",
        "\n",
        "avg_fit_time = np.mean(fit_times)\n",
        "avg_generate_time = np.mean(generate_times)\n",
        "std_fit_time = np.std(fit_times)\n",
        "std_generate_time = np.std(generate_times)\n",
        "\n",
        "print(f\"\\nAverage Fit Time: {avg_fit_time:.4f} seconds, Standard Deviation: {std_fit_time:.4f} seconds\")\n",
        "print(f\"Average Generate Time: {avg_generate_time:.4f} seconds, Standard Deviation: {std_generate_time:.4f} seconds\")\n"
      ],
      "metadata": {
        "id": "72hH1d80Lg0l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result_df"
      ],
      "metadata": {
        "id": "YfSQP6yLiTxj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "p_values_df"
      ],
      "metadata": {
        "id": "i92Q1Z7jiToM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tVnRTBHHCt0d"
      },
      "source": [
        "# AIDS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XLWVp7FlVHdD"
      },
      "outputs": [],
      "source": [
        "dataset=\"aids\"\n",
        "\n",
        "metrics_list = []\n",
        "fit_times = []\n",
        "generate_times = []\n",
        "p_values_list = []\n",
        "\n",
        "for i in range(5):\n",
        "    df = pd.read_csv('/content/drive/MyDrive/Datasets/aids.csv')\n",
        "    df = df.drop('Unnamed: 0', axis=1)\n",
        "    df = df[df['duration'] != 0]\n",
        "\n",
        "    time = df['duration'].to_list()\n",
        "    event = df['event'].to_list()\n",
        "\n",
        "    time_event_encoded = sinusoidal_embedding(time, event, 4)\n",
        "    X = df.drop(['duration', 'event'], axis=1)\n",
        "    y = time_event_encoded\n",
        "\n",
        "    syn_model = Plugins().get(plugin_name)\n",
        "\n",
        "    # Measure the execution time of the fit function\n",
        "    start = timer()\n",
        "    syn_model.fit(X, cond=y)\n",
        "    fit_time = timer() - start\n",
        "    fit_times.append(fit_time)\n",
        "\n",
        "    survival_df=df\n",
        "    event_0_data = survival_df[survival_df['event'] == 0]['duration'].values\n",
        "    event_1_data = survival_df[survival_df['event'] == 1]['duration'].values\n",
        "\n",
        "    random_state = i + 1\n",
        "    np.random.seed(random_state)\n",
        "\n",
        "    # Use KDE to sample time values for each event type\n",
        "    sample_size_0 = len(event_0_data)\n",
        "    sample_size_1 = len(event_1_data)\n",
        "\n",
        "    # Sample from KDE for each event type\n",
        "    sample_event_0 = fit_dpmm_and_sample(event_0_data, sample_size_0,integer_sampling=True)\n",
        "    sample_event_1 = fit_dpmm_and_sample(event_1_data, sample_size_1,integer_sampling=True)\n",
        "\n",
        "    z=np.concatenate([sample_event_0,sample_event_1])\n",
        "    x=np.zeros(len(sample_event_0))\n",
        "    y=np.ones(len(sample_event_1))\n",
        "    p=np.concatenate([x,y])\n",
        "\n",
        "    time_event_gen_encoded=sinusoidal_embedding(z,p,4)\n",
        "\n",
        "    # Measure the execution time of the generate function\n",
        "    start = timer()\n",
        "    X_gen = syn_model.generate(count=len(df), cond=np.array(time_event_gen_encoded)).dataframe()\n",
        "    generate_time = timer() - start\n",
        "    generate_times.append(generate_time)\n",
        "\n",
        "    X_gen['duration'] = z\n",
        "    X_gen['event'] = p\n",
        "    X_gen = X_gen.sample(frac=1).reset_index(drop=True)\n",
        "\n",
        "    # Save X_gen as a CSV file\n",
        "    X_gen.to_csv(f\"/content/drive/MyDrive/ICML/{dataset}_{plugin_name}_iteration_{i+1}.csv\", index=False)\n",
        "\n",
        "    loader1 = SurvivalAnalysisDataLoader(df, target_column=\"event\", time_to_event_column=\"duration\")\n",
        "    loader2 = SurvivalAnalysisDataLoader(X_gen, target_column=\"event\", time_to_event_column=\"duration\")\n",
        "\n",
        "    met_df = Metrics.evaluate(X_gt=loader1, X_syn=loader2, task_type='survival_analysis',\n",
        "                              metrics={\n",
        "        'stats': ['jensenshannon_dist', 'chi_squared_test', 'feature_corr', 'inv_kl_divergence', 'ks_test',\n",
        "                 'max_mean_discrepancy', 'wasserstein_dist', 'prdc', 'alpha_precision', 'survival_km_distance'],\n",
        "        'performance': ['linear_model', 'mlp', 'xgb', 'feat_rank_distance']\n",
        "    },\n",
        "        use_cache=False, random_state=random_state)\n",
        "\n",
        "    met_df = met_df.iloc[:, 0]\n",
        "    metrics_list.append(met_df)\n",
        "\n",
        "    # Calculate p-values\n",
        "    p_values_continuous, p_values_discrete = compare_distributions(df, X_gen)\n",
        "    continuous_column_names = list(p_values_continuous.keys())\n",
        "    discrete_column_names = list(p_values_discrete.keys())\n",
        "\n",
        "    p_val = np.concatenate([list(p_values_continuous.values()), list(p_values_discrete.values())])\n",
        "    p_values_list.append(p_val)\n",
        "\n",
        "    workspace_dir = os.path.join(os.getcwd(), 'workspace')\n",
        "    if os.path.exists(workspace_dir):\n",
        "        shutil.rmtree(workspace_dir)\n",
        "\n",
        "result_df = pd.concat(metrics_list, axis=1)\n",
        "\n",
        "# Calculate the row-wise mean and standard deviation of the metrics\n",
        "result_df['Mean'] = result_df.mean(axis=1)\n",
        "result_df['Std'] = result_df.std(axis=1)\n",
        "result_df['Std'] = result_df['Std'].round(4)\n",
        "\n",
        "# Create DataFrame for p-values\n",
        "p_values_df = pd.DataFrame(p_values_list, columns=continuous_column_names + discrete_column_names)\n",
        "\n",
        "# Save result_df and p_values_df as CSV files\n",
        "result_df.to_csv(f\"/content/drive/MyDrive/ICML/{dataset}_{plugin_name}_result_df.csv\")\n",
        "p_values_df.to_csv(f\"/content/drive/MyDrive/ICML/{dataset}_{plugin_name}_p_values_df.csv\")\n",
        "\n",
        "avg_fit_time = np.mean(fit_times)\n",
        "avg_generate_time = np.mean(generate_times)\n",
        "std_fit_time = np.std(fit_times)\n",
        "std_generate_time = np.std(generate_times)\n",
        "\n",
        "print(f\"\\nAverage Fit Time: {avg_fit_time:.4f} seconds, Standard Deviation: {std_fit_time:.4f} seconds\")\n",
        "print(f\"Average Generate Time: {avg_generate_time:.4f} seconds, Standard Deviation: {std_generate_time:.4f} seconds\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dHBJijmUYIew"
      },
      "outputs": [],
      "source": [
        "result_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "euNS1tINYKCm"
      },
      "outputs": [],
      "source": [
        "p_values_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2jJPOKXocEu6"
      },
      "source": [
        "# Metabric"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "40akL9o-2xuG"
      },
      "outputs": [],
      "source": [
        "dataset=\"metabric\"\n",
        "\n",
        "metrics_list = []\n",
        "fit_times = []\n",
        "generate_times = []\n",
        "p_values_list = []\n",
        "\n",
        "for i in range(5):\n",
        "    df = datasets.metabric.read_df()\n",
        "    df = df[df['duration'] != 0]\n",
        "\n",
        "    time = df['duration'].to_list()\n",
        "    event = df['event'].to_list()\n",
        "\n",
        "    time_event_encoded = sinusoidal_embedding(time, event, 4)\n",
        "    X = df.drop(['duration', 'event'], axis=1)\n",
        "    y = time_event_encoded\n",
        "\n",
        "    syn_model = Plugins().get(plugin_name)\n",
        "\n",
        "    # Measure the execution time of the fit function\n",
        "    start = timer()\n",
        "    syn_model.fit(X, cond=y)\n",
        "    fit_time = timer() - start\n",
        "    fit_times.append(fit_time)\n",
        "\n",
        "    survival_df=df\n",
        "    event_0_data = survival_df[survival_df['event'] == 0]['duration'].values\n",
        "    event_1_data = survival_df[survival_df['event'] == 1]['duration'].values\n",
        "\n",
        "    random_state = i + 1\n",
        "    np.random.seed(random_state)\n",
        "\n",
        "    # Use KDE to sample time values for each event type\n",
        "    sample_size_0 = len(event_0_data)\n",
        "    sample_size_1 = len(event_1_data)\n",
        "\n",
        "    # Sample from KDE for each event type\n",
        "    sample_event_0 = fit_dpmm_and_sample(event_0_data, sample_size_0,integer_sampling=False)\n",
        "    sample_event_1 = fit_dpmm_and_sample(event_1_data, sample_size_1,integer_sampling=False)\n",
        "\n",
        "    z=np.concatenate([sample_event_0,sample_event_1])\n",
        "    x=np.zeros(len(sample_event_0))\n",
        "    y=np.ones(len(sample_event_1))\n",
        "    p=np.concatenate([x,y])\n",
        "\n",
        "    time_event_gen_encoded=sinusoidal_embedding(z,p,4)\n",
        "\n",
        "    # Measure the execution time of the generate function\n",
        "    start = timer()\n",
        "    X_gen = syn_model.generate(count=len(df), cond=np.array(time_event_gen_encoded)).dataframe()\n",
        "    generate_time = timer() - start\n",
        "    generate_times.append(generate_time)\n",
        "\n",
        "    X_gen['duration'] = z\n",
        "    X_gen['event'] = p\n",
        "    X_gen = X_gen.sample(frac=1).reset_index(drop=True)\n",
        "\n",
        "    # Save X_gen as a CSV file\n",
        "    X_gen.to_csv(f\"/content/drive/MyDrive/ICML/{dataset}_{plugin_name}_iteration_{i+1}.csv\", index=False)\n",
        "\n",
        "    loader1 = SurvivalAnalysisDataLoader(df, target_column=\"event\", time_to_event_column=\"duration\")\n",
        "    loader2 = SurvivalAnalysisDataLoader(X_gen, target_column=\"event\", time_to_event_column=\"duration\")\n",
        "\n",
        "    met_df = Metrics.evaluate(X_gt=loader1, X_syn=loader2, task_type='survival_analysis', metrics={\n",
        "        'stats': ['jensenshannon_dist', 'chi_squared_test', 'feature_corr', 'inv_kl_divergence', 'ks_test',\n",
        "                 'max_mean_discrepancy', 'wasserstein_dist', 'prdc', 'alpha_precision', 'survival_km_distance'],\n",
        "        'performance': ['linear_model', 'mlp', 'xgb', 'feat_rank_distance']\n",
        "    }, use_cache=False, random_state=random_state)\n",
        "\n",
        "    met_df = met_df.iloc[:, 0]\n",
        "    metrics_list.append(met_df)\n",
        "\n",
        "    # Calculate p-values\n",
        "    p_values_continuous, p_values_discrete = compare_distributions(df, X_gen)\n",
        "    continuous_column_names = list(p_values_continuous.keys())\n",
        "    discrete_column_names = list(p_values_discrete.keys())\n",
        "\n",
        "    p_val = np.concatenate([list(p_values_continuous.values()), list(p_values_discrete.values())])\n",
        "    p_values_list.append(p_val)\n",
        "\n",
        "    workspace_dir = os.path.join(os.getcwd(), 'workspace')\n",
        "    if os.path.exists(workspace_dir):\n",
        "        shutil.rmtree(workspace_dir)\n",
        "\n",
        "result_df = pd.concat(metrics_list, axis=1)\n",
        "\n",
        "# Calculate the row-wise mean and standard deviation of the metrics\n",
        "result_df['Mean'] = result_df.mean(axis=1)\n",
        "result_df['Std'] = result_df.std(axis=1)\n",
        "result_df['Std'] = result_df['Std'].round(4)\n",
        "\n",
        "# Create DataFrame for p-values\n",
        "p_values_df = pd.DataFrame(p_values_list, columns=continuous_column_names + discrete_column_names)\n",
        "\n",
        "# Save result_df and p_values_df as CSV files\n",
        "result_df.to_csv(f\"/content/drive/MyDrive/ICML/{dataset}_{plugin_name}_result_df.csv\")\n",
        "p_values_df.to_csv(f\"/content/drive/MyDrive/ICML/{dataset}_{plugin_name}_p_values_df.csv\")\n",
        "\n",
        "avg_fit_time = np.mean(fit_times)\n",
        "avg_generate_time = np.mean(generate_times)\n",
        "std_fit_time = np.std(fit_times)\n",
        "std_generate_time = np.std(generate_times)\n",
        "\n",
        "print(f\"\\nAverage Fit Time: {avg_fit_time:.4f} seconds, Standard Deviation: {std_fit_time:.4f} seconds\")\n",
        "print(f\"Average Generate Time: {avg_generate_time:.4f} seconds, Standard Deviation: {std_generate_time:.4f} seconds\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MCmPsJdX2xng"
      },
      "outputs": [],
      "source": [
        "result_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kWZ9aI4i2xf1"
      },
      "outputs": [],
      "source": [
        "p_values_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Q90MorO3YqW"
      },
      "source": [
        "# GBSG"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J_vUdi722-V3"
      },
      "outputs": [],
      "source": [
        "dataset=\"gbsg\"\n",
        "\n",
        "metrics_list = []\n",
        "fit_times = []\n",
        "generate_times = []\n",
        "p_values_list = []\n",
        "\n",
        "for i in range(5):\n",
        "    df = datasets.gbsg.read_df()\n",
        "    df = df[df['duration'] != 0]\n",
        "\n",
        "    time = df['duration'].to_list()\n",
        "    event = df['event'].to_list()\n",
        "\n",
        "    time_event_encoded = sinusoidal_embedding(time, event, 4)\n",
        "    X = df.drop(['duration', 'event'], axis=1)\n",
        "    y = time_event_encoded\n",
        "\n",
        "    syn_model = Plugins().get(plugin_name)\n",
        "\n",
        "    # Measure the execution time of the fit function\n",
        "    start = timer()\n",
        "    syn_model.fit(X, cond=y)\n",
        "    fit_time = timer() - start\n",
        "    fit_times.append(fit_time)\n",
        "\n",
        "    survival_df=df\n",
        "    event_0_data = survival_df[survival_df['event'] == 0]['duration'].values\n",
        "    event_1_data = survival_df[survival_df['event'] == 1]['duration'].values\n",
        "\n",
        "    random_state = i + 1\n",
        "    np.random.seed(random_state)\n",
        "\n",
        "    # Use KDE to sample time values for each event type\n",
        "    sample_size_0 = len(event_0_data)\n",
        "    sample_size_1 = len(event_1_data)\n",
        "\n",
        "    # Sample from KDE for each event type\n",
        "    sample_event_0 = fit_dpmm_and_sample(event_0_data, sample_size_0,integer_sampling=False)\n",
        "    sample_event_1 = fit_dpmm_and_sample(event_1_data, sample_size_1,integer_sampling=False)\n",
        "\n",
        "    z=np.concatenate([sample_event_0,sample_event_1])\n",
        "    x=np.zeros(len(sample_event_0))\n",
        "    y=np.ones(len(sample_event_1))\n",
        "    p=np.concatenate([x,y])\n",
        "\n",
        "    time_event_gen_encoded=sinusoidal_embedding(z,p,4)\n",
        "\n",
        "    # Measure the execution time of the generate function\n",
        "    start = timer()\n",
        "    X_gen = syn_model.generate(count=len(df), cond=np.array(time_event_gen_encoded)).dataframe()\n",
        "    generate_time = timer() - start\n",
        "    generate_times.append(generate_time)\n",
        "\n",
        "    X_gen['duration'] = z\n",
        "    X_gen['event'] = p\n",
        "    X_gen = X_gen.sample(frac=1).reset_index(drop=True)\n",
        "\n",
        "    # Save X_gen as a CSV file\n",
        "    X_gen.to_csv(f\"/content/drive/MyDrive/ICML/{dataset}_{plugin_name}_iteration_{i+1}.csv\", index=False)\n",
        "\n",
        "    loader1 = SurvivalAnalysisDataLoader(df, target_column=\"event\", time_to_event_column=\"duration\")\n",
        "    loader2 = SurvivalAnalysisDataLoader(X_gen, target_column=\"event\", time_to_event_column=\"duration\")\n",
        "\n",
        "    met_df = Metrics.evaluate(X_gt=loader1, X_syn=loader2, task_type='survival_analysis', metrics={\n",
        "        'stats': ['jensenshannon_dist', 'chi_squared_test', 'feature_corr', 'inv_kl_divergence', 'ks_test',\n",
        "                 'max_mean_discrepancy', 'wasserstein_dist', 'prdc', 'alpha_precision', 'survival_km_distance'],\n",
        "        'performance': ['linear_model', 'mlp', 'xgb', 'feat_rank_distance']\n",
        "    }, use_cache=False, random_state=random_state)\n",
        "\n",
        "    met_df = met_df.iloc[:, 0]\n",
        "    metrics_list.append(met_df)\n",
        "\n",
        "    # Calculate p-values\n",
        "    p_values_continuous, p_values_discrete = compare_distributions(df, X_gen)\n",
        "    continuous_column_names = list(p_values_continuous.keys())\n",
        "    discrete_column_names = list(p_values_discrete.keys())\n",
        "\n",
        "    p_val = np.concatenate([list(p_values_continuous.values()), list(p_values_discrete.values())])\n",
        "    p_values_list.append(p_val)\n",
        "\n",
        "    workspace_dir = os.path.join(os.getcwd(), 'workspace')\n",
        "    if os.path.exists(workspace_dir):\n",
        "        shutil.rmtree(workspace_dir)\n",
        "\n",
        "result_df = pd.concat(metrics_list, axis=1)\n",
        "\n",
        "# Calculate the row-wise mean and standard deviation of the metrics\n",
        "result_df['Mean'] = result_df.mean(axis=1)\n",
        "result_df['Std'] = result_df.std(axis=1)\n",
        "result_df['Std'] = result_df['Std'].round(4)\n",
        "\n",
        "# Create DataFrame for p-values\n",
        "p_values_df = pd.DataFrame(p_values_list, columns=continuous_column_names + discrete_column_names)\n",
        "\n",
        "# Save result_df and p_values_df as CSV files\n",
        "result_df.to_csv(f\"/content/drive/MyDrive/ICML/{dataset}_{plugin_name}_result_df.csv\")\n",
        "p_values_df.to_csv(f\"/content/drive/MyDrive/ICML/{dataset}_{plugin_name}_p_values_df.csv\")\n",
        "\n",
        "avg_fit_time = np.mean(fit_times)\n",
        "avg_generate_time = np.mean(generate_times)\n",
        "std_fit_time = np.std(fit_times)\n",
        "std_generate_time = np.std(generate_times)\n",
        "\n",
        "print(f\"\\nAverage Fit Time: {avg_fit_time:.4f} seconds, Standard Deviation: {std_fit_time:.4f} seconds\")\n",
        "print(f\"Average Generate Time: {avg_generate_time:.4f} seconds, Standard Deviation: {std_generate_time:.4f} seconds\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CmUmr6x-294_"
      },
      "outputs": [],
      "source": [
        "result_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aYZaCxoW3gN4"
      },
      "outputs": [],
      "source": [
        "p_values_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rf0dJwdN3iHi"
      },
      "source": [
        "# SUPPORT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pzp6chZi3lbt"
      },
      "outputs": [],
      "source": [
        "dataset=\"support\"\n",
        "\n",
        "metrics_list = []\n",
        "fit_times = []\n",
        "generate_times = []\n",
        "p_values_list = []\n",
        "\n",
        "for i in range(5):\n",
        "    df = datasets.support.read_df()\n",
        "    df = df[df['duration'] != 0]\n",
        "\n",
        "    time = df['duration'].to_list()\n",
        "    event = df['event'].to_list()\n",
        "\n",
        "    time_event_encoded = sinusoidal_embedding(time, event, 4)\n",
        "    X = df.drop(['duration', 'event'], axis=1)\n",
        "    y = time_event_encoded\n",
        "\n",
        "    syn_model = Plugins().get(plugin_name)\n",
        "\n",
        "    # Measure the execution time of the fit function\n",
        "    start = timer()\n",
        "    syn_model.fit(X, cond=y)\n",
        "    fit_time = timer() - start\n",
        "    fit_times.append(fit_time)\n",
        "\n",
        "    survival_df=df\n",
        "    event_0_data = survival_df[survival_df['event'] == 0]['duration'].values\n",
        "    event_1_data = survival_df[survival_df['event'] == 1]['duration'].values\n",
        "\n",
        "    random_state = i + 1\n",
        "    np.random.seed(random_state)\n",
        "\n",
        "    # Use KDE to sample time values for each event type\n",
        "    sample_size_0 = len(event_0_data)\n",
        "    sample_size_1 = len(event_1_data)\n",
        "\n",
        "    # Sample from KDE for each event type\n",
        "    sample_event_0 = fit_dpmm_and_sample(event_0_data, sample_size_0,integer_sampling=True)\n",
        "    sample_event_1 = fit_dpmm_and_sample(event_1_data, sample_size_1,integer_sampling=True)\n",
        "\n",
        "    z=np.concatenate([sample_event_0,sample_event_1])\n",
        "    x=np.zeros(len(sample_event_0))\n",
        "    y=np.ones(len(sample_event_1))\n",
        "    p=np.concatenate([x,y])\n",
        "\n",
        "    time_event_gen_encoded=sinusoidal_embedding(z,p,4)\n",
        "\n",
        "    # Measure the execution time of the generate function\n",
        "    start = timer()\n",
        "    X_gen = syn_model.generate(count=len(df), cond=np.array(time_event_gen_encoded)).dataframe()\n",
        "    generate_time = timer() - start\n",
        "    generate_times.append(generate_time)\n",
        "\n",
        "    X_gen['duration'] = z\n",
        "    X_gen['event'] = p\n",
        "    X_gen = X_gen.sample(frac=1).reset_index(drop=True)\n",
        "\n",
        "    # Save X_gen as a CSV file\n",
        "    X_gen.to_csv(f\"/content/drive/MyDrive/ICML/{dataset}_{plugin_name}_iteration_{i+1}.csv\", index=False)\n",
        "\n",
        "    loader1 = SurvivalAnalysisDataLoader(df, target_column=\"event\", time_to_event_column=\"duration\")\n",
        "    loader2 = SurvivalAnalysisDataLoader(X_gen, target_column=\"event\", time_to_event_column=\"duration\")\n",
        "\n",
        "    met_df = Metrics.evaluate(X_gt=loader1, X_syn=loader2, task_type='survival_analysis', metrics={\n",
        "        'stats': ['jensenshannon_dist', 'chi_squared_test', 'feature_corr', 'inv_kl_divergence', 'ks_test',\n",
        "                 'max_mean_discrepancy', 'wasserstein_dist', 'prdc', 'alpha_precision', 'survival_km_distance'],\n",
        "        'performance': ['linear_model', 'mlp', 'xgb', 'feat_rank_distance']\n",
        "    }, use_cache=False, random_state=random_state)\n",
        "\n",
        "    met_df = met_df.iloc[:, 0]\n",
        "    metrics_list.append(met_df)\n",
        "\n",
        "    # Calculate p-values\n",
        "    p_values_continuous, p_values_discrete = compare_distributions(df, X_gen)\n",
        "    continuous_column_names = list(p_values_continuous.keys())\n",
        "    discrete_column_names = list(p_values_discrete.keys())\n",
        "\n",
        "    p_val = np.concatenate([list(p_values_continuous.values()), list(p_values_discrete.values())])\n",
        "    p_values_list.append(p_val)\n",
        "\n",
        "    workspace_dir = os.path.join(os.getcwd(), 'workspace')\n",
        "    if os.path.exists(workspace_dir):\n",
        "        shutil.rmtree(workspace_dir)\n",
        "\n",
        "result_df = pd.concat(metrics_list, axis=1)\n",
        "\n",
        "# Calculate the row-wise mean and standard deviation of the metrics\n",
        "result_df['Mean'] = result_df.mean(axis=1)\n",
        "result_df['Std'] = result_df.std(axis=1)\n",
        "result_df['Std'] = result_df['Std'].round(4)\n",
        "\n",
        "# Create DataFrame for p-values\n",
        "p_values_df = pd.DataFrame(p_values_list, columns=continuous_column_names + discrete_column_names)\n",
        "\n",
        "# Save result_df and p_values_df as CSV files\n",
        "result_df.to_csv(f\"/content/drive/MyDrive/ICML/{dataset}_{plugin_name}_result_df.csv\")\n",
        "p_values_df.to_csv(f\"/content/drive/MyDrive/ICML/{dataset}_{plugin_name}_p_values_df.csv\")\n",
        "\n",
        "avg_fit_time = np.mean(fit_times)\n",
        "avg_generate_time = np.mean(generate_times)\n",
        "std_fit_time = np.std(fit_times)\n",
        "std_generate_time = np.std(generate_times)\n",
        "\n",
        "print(f\"\\nAverage Fit Time: {avg_fit_time:.4f} seconds, Standard Deviation: {std_fit_time:.4f} seconds\")\n",
        "print(f\"Average Generate Time: {avg_generate_time:.4f} seconds, Standard Deviation: {std_generate_time:.4f} seconds\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CBW3qLE73lYP"
      },
      "outputs": [],
      "source": [
        "result_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i-v0i0Yu3lUw"
      },
      "outputs": [],
      "source": [
        "p_values_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pvMBYUJV50Vh"
      },
      "source": [
        "**bold text**# FLCHAIN"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}