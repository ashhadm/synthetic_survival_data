{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from synthcity.plugins.core.dataloader import SurvivalAnalysisDataLoader\n",
        "from synthcity.metrics import Metrics\n",
        "import os"
      ],
      "metadata": {
        "id": "3OCaN6Am8PJ0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def benchmark_limited_data_experiment():\n",
        "    \"\"\"\n",
        "    Benchmark code for Table 4: Performance comparison with reduced training data on AIDS dataset\n",
        "    \"\"\"\n",
        "\n",
        "    # Dataset and methods configuration\n",
        "    dataset = \"aids\"  # Using AIDS dataset as specified in Table 4\n",
        "    data_percentages = [100, 75, 50]  # Training data percentages\n",
        "    methods = [\"ours\", \"unconditional\", \"survivalgan\"]\n",
        "\n",
        "    # Define folder paths containing the 5 different datasets for each method\n",
        "    # Adjust these paths according to your file structure\n",
        "    data_paths = {\n",
        "        \"ours\": \".../ours_datasets/\",\n",
        "        \"unconditional\": \".../unconditional_datasets/\",\n",
        "        \"survivalgan\": \".../survivalgan_datasets/\"\n",
        "    }\n",
        "\n",
        "    # Path to original AIDS dataset\n",
        "    original_data_path = \".../aids_final.csv\"\n",
        "\n",
        "    # Load original dataset\n",
        "    df_original = pd.read_csv(original_data_path)\n",
        "    if 'Unnamed: 0' in df_original.columns:\n",
        "        df_original = df_original.drop('Unnamed: 0', axis=1)\n",
        "    df_original = df_original[df_original['duration'] != 0]\n",
        "\n",
        "    # Initialize results storage\n",
        "    all_results = {}\n",
        "\n",
        "    for percentage in data_percentages:\n",
        "        print(f\"\\n=== Evaluating {percentage}% Training Data ===\")\n",
        "        all_results[percentage] = {}\n",
        "\n",
        "        for method in methods:\n",
        "            print(f\"Processing method: {method}\")\n",
        "\n",
        "            # Storage for metrics across iterations\n",
        "            metrics_list = []\n",
        "\n",
        "            # Process 5 different datasets (one for each iteration)\n",
        "            for iteration in range(1, 6):\n",
        "                try:\n",
        "                    # Load different synthetic dataset for each iteration\n",
        "                    # Assumes datasets are named like: aids_ours_1.csv, aids_ours_2.csv, etc.\n",
        "                    synthetic_filename = f\"{dataset}_{method}_{iteration}.csv\"\n",
        "                    synthetic_path = os.path.join(data_paths[method], synthetic_filename)\n",
        "\n",
        "                    if not os.path.exists(synthetic_path):\n",
        "                        print(f\"Warning: File not found: {synthetic_path}\")\n",
        "                        continue\n",
        "\n",
        "                    df_synthetic_full = pd.read_csv(synthetic_path)\n",
        "\n",
        "                    # Ensure synthetic data has same structure\n",
        "                    if 'Unnamed: 0' in df_synthetic_full.columns:\n",
        "                        df_synthetic_full = df_synthetic_full.drop('Unnamed: 0', axis=1)\n",
        "\n",
        "                    # Sample the desired percentage of data\n",
        "                    if percentage == 100:\n",
        "                        df_synthetic = df_synthetic_full.copy()\n",
        "                    else:\n",
        "                        sample_size = int(len(df_synthetic_full) * (percentage / 100))\n",
        "                        df_synthetic = df_synthetic_full.sample(n=sample_size, random_state=42).reset_index(drop=True)\n",
        "\n",
        "                    # Create data loaders for evaluation\n",
        "                    loader_original = SurvivalAnalysisDataLoader(\n",
        "                        df_original,\n",
        "                        target_column=\"event\",\n",
        "                        time_to_event_column=\"duration\"\n",
        "                    )\n",
        "                    loader_synthetic = SurvivalAnalysisDataLoader(\n",
        "                        df_synthetic,\n",
        "                        target_column=\"event\",\n",
        "                        time_to_event_column=\"duration\"\n",
        "                    )\n",
        "\n",
        "                    # Evaluate metrics using synthcity\n",
        "                    met_df = Metrics.evaluate(\n",
        "                        X_gt=loader_original,\n",
        "                        X_syn=loader_synthetic,\n",
        "                        task_type='survival_analysis',\n",
        "                        metrics={\n",
        "                            'stats': [\n",
        "                                'jensenshannon_dist', 'chi_squared_test', 'feature_corr',\n",
        "                                'inv_kl_divergence', 'ks_test', 'max_mean_discrepancy',\n",
        "                                'wasserstein_dist', 'prdc', 'alpha_precision', 'survival_km_distance'\n",
        "                            ],\n",
        "                            'performance': ['linear_model', 'mlp', 'xgb', 'feat_rank_distance']\n",
        "                        },\n",
        "                        use_cache=False,\n",
        "                        random_state=iteration\n",
        "                    )\n",
        "\n",
        "                    met_df = met_df.iloc[:, 0]\n",
        "                    metrics_list.append(met_df)\n",
        "\n",
        "                    print(f\"  Dataset {iteration} completed (using {synthetic_filename}, sampled {len(df_synthetic)} rows from {len(df_synthetic_full)})\")\n",
        "\n",
        "                except Exception as e:\n",
        "                    print(f\"  Error in dataset {iteration}: {str(e)}\")\n",
        "                    continue\n",
        "\n",
        "            # Create result_df \n",
        "            if len(metrics_list) > 0:\n",
        "                result_df = pd.concat(metrics_list, axis=1)\n",
        "\n",
        "                # Calculate the row-wise mean and standard deviation of the metrics\n",
        "                result_df['Mean'] = result_df.mean(axis=1)\n",
        "                result_df['Std'] = result_df.std(axis=1)\n",
        "                result_df['Std'] = result_df['Std'].round(4)\n",
        "\n",
        "                all_results[percentage][method] = result_df\n",
        "            else:\n",
        "                print(f\"  No valid data found for {method} at {percentage}%\")\n",
        "                all_results[percentage][method] = None\n",
        "\n",
        "    return all_results\n",
        "\n",
        "\n",
        "\n",
        "# Main execution\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"Starting Table 4 benchmark evaluation...\")\n",
        "\n",
        "    # Run the benchmark\n",
        "    all_results = benchmark_limited_data_experiment()\n",
        "\n",
        "    # Print results_df for each method and percentage combination\n",
        "    for percentage in [100, 75, 50]:\n",
        "        print(f\"\\n{'='*60}\")\n",
        "        print(f\"{percentage}% Training Data Results\")\n",
        "        print(f\"{'='*60}\")\n",
        "\n",
        "        for method in ['ours', 'unconditional', 'survivalgan']:\n",
        "            if percentage in all_results and method in all_results[percentage] and all_results[percentage][method] is not None:\n",
        "                print(f\"\\n{method.upper()} Method:\")\n",
        "                print(all_results[percentage][method])\n",
        "            else:\n",
        "                print(f\"\\n{method.upper()} Method: No data available\")\n",
        "\n",
        "    print(\"\\nTable 4 benchmark evaluation completed!\")"
      ],
      "metadata": {
        "id": "jUj7n8Qu9hCv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
