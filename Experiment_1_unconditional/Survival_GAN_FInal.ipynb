{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q4t0avdQCPZL"
      },
      "outputs": [],
      "source": [
        "!pip install git+https://github.com/anonymous-785/synthcity.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall -y torchaudio torchdata\n",
        "!pip install pycox\n",
        "from pycox import datasets\n",
        "from synthcity.metrics import Metrics\n",
        "from synthcity.plugins.core.dataloader import SurvivalAnalysisDataLoader\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import shutil\n",
        "from timeit import default_timer as timer\n",
        "from synthcity.plugins import Plugins"
      ],
      "metadata": {
        "id": "CEODMo6FCSqm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plugin_name=\"survival_gan\""
      ],
      "metadata": {
        "id": "EHCownpHdrh1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Functions"
      ],
      "metadata": {
        "id": "g66l69NIdwo0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats import mannwhitneyu, chi2_contingency,wilcoxon\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def identify_variable_types(df):\n",
        "    continuous_columns = []\n",
        "    discrete_columns = []\n",
        "\n",
        "    for col in df.columns:\n",
        "        unique_vals = df[col].unique()\n",
        "        num_unique = len(unique_vals)\n",
        "        if num_unique > 20:  # Threshold for considering a column as continuous\n",
        "            continuous_columns.append(col)\n",
        "        else:\n",
        "            discrete_columns.append(col)\n",
        "\n",
        "    return continuous_columns, discrete_columns\n",
        "\n",
        "def compare_distributions(real_df, synthetic_df, alpha=0.05):\n",
        "    real_df = real_df.drop(['duration', 'event'], axis=1)\n",
        "    real_continuous, real_discrete = identify_variable_types(real_df)\n",
        "    p_values_continuous = {}\n",
        "    p_values_discrete = {}\n",
        "\n",
        "    synthetic_df = synthetic_df.drop(['duration', 'event'], axis=1)\n",
        "    synthetic_continuous, synthetic_discrete = identify_variable_types(synthetic_df)\n",
        "\n",
        "    synthetic_continuous = [col for col in synthetic_continuous if col not in [\"event\", \"duration\"]]\n",
        "    synthetic_discrete = [col for col in synthetic_discrete if col not in [\"event\", \"duration\"]]\n",
        "\n",
        "    # Wilcoxon rank-sum test for continuous variables\n",
        "    for col in real_continuous:\n",
        "        if col in synthetic_continuous:\n",
        "            _, p_value = mannwhitneyu(real_df[col], synthetic_df[col])\n",
        "            p_values_continuous[col] = p_value\n",
        "\n",
        "    # Chi-square test for discrete variables\n",
        "    for col in real_discrete:\n",
        "        if col in synthetic_discrete:\n",
        "            contingency_table = pd.crosstab(real_df[col], synthetic_df[col])\n",
        "            _, p, _, _ = chi2_contingency(contingency_table)\n",
        "            p_values_discrete[col] = p\n",
        "\n",
        "    # Plot p-values\n",
        "    # plt.figure(figsize=(10, 6))\n",
        "\n",
        "    # continuous_p_values = {col: p_values_continuous[col] for col in real_continuous}\n",
        "    # discrete_p_values = {col: p_values_discrete[col] for col in real_discrete}\n",
        "\n",
        "    # plt.plot(list(continuous_p_values.keys()), list(continuous_p_values.values()), label='Continuous', marker='o')\n",
        "    # plt.plot(list(discrete_p_values.keys()), list(discrete_p_values.values()), label='Discrete', marker='o', linestyle='dashed')\n",
        "\n",
        "    # # Plot alpha line\n",
        "    # plt.axhline(y=alpha, color='red', linestyle='--', label=f'alpha = {alpha}')\n",
        "\n",
        "    # plt.xlabel('Column Name')\n",
        "    # plt.ylabel('p-value')\n",
        "    # plt.title('Comparison of p-values for Real and Synthetic Data')\n",
        "    # plt.xticks(rotation=45)\n",
        "    # plt.legend()\n",
        "    # plt.grid(True)\n",
        "    # plt.tight_layout()\n",
        "    # plt.show()\n",
        "\n",
        "    return p_values_continuous, p_values_discrete\n",
        "\n"
      ],
      "metadata": {
        "id": "iw4DqUnXCjNr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# FLCHAIN"
      ],
      "metadata": {
        "id": "7IShX9WWh437"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset=\"flchain\"\n",
        "\n",
        "metrics_list = []\n",
        "fit_times = []\n",
        "generate_times = []\n",
        "p_values_list = []\n",
        "\n",
        "for i in range(5):\n",
        "    df = pd.read_csv('/content/drive/MyDrive/Datasets/flchain_final.csv')\n",
        "    df = df.drop('Unnamed: 0', axis=1)\n",
        "    df = df[df['duration'] != 0]\n",
        "\n",
        "    loader = SurvivalAnalysisDataLoader(\n",
        "    df,\n",
        "    target_column=\"event\",\n",
        "    time_to_event_column=\"duration\",\n",
        "    )\n",
        "\n",
        "\n",
        "    syn_model = Plugins().get(plugin_name)\n",
        "\n",
        "    # Measure the execution time of the fit function\n",
        "    start = timer()\n",
        "    syn_model.fit(loader)\n",
        "    fit_time = timer() - start\n",
        "    fit_times.append(fit_time)\n",
        "\n",
        "    random_state = i + 1\n",
        "    np.random.seed(random_state)\n",
        "\n",
        "    # Measure the execution time of the generate function\n",
        "    start = timer()\n",
        "    X_gen = syn_model.generate(count=len(df)).dataframe()\n",
        "    generate_time = timer() - start\n",
        "    generate_times.append(generate_time)\n",
        "\n",
        "    # Save X_gen as a CSV file\n",
        "    X_gen.to_csv(f\"/content/drive/MyDrive/Nips/{dataset}_{plugin_name}_iteration_{i+1}.csv\", index=False)\n",
        "\n",
        "    loader1 = SurvivalAnalysisDataLoader(df, target_column=\"event\", time_to_event_column=\"duration\")\n",
        "    loader2 = SurvivalAnalysisDataLoader(X_gen, target_column=\"event\", time_to_event_column=\"duration\")\n",
        "\n",
        "    met_df = Metrics.evaluate(X_gt=loader1, X_syn=loader2, task_type='survival_analysis', metrics={\n",
        "        'stats': ['jensenshannon_dist', 'chi_squared_test', 'feature_corr', 'inv_kl_divergence', 'ks_test',\n",
        "                 'max_mean_discrepancy', 'wasserstein_dist', 'prdc', 'alpha_precision', 'survival_km_distance'],\n",
        "        'performance': ['linear_model', 'mlp', 'xgb', 'feat_rank_distance']\n",
        "    }, use_cache=False, random_state=random_state)\n",
        "\n",
        "    met_df = met_df.iloc[:, 0]\n",
        "    metrics_list.append(met_df)\n",
        "\n",
        "    # Calculate p-values\n",
        "    p_values_continuous, p_values_discrete = compare_distributions(df, X_gen)\n",
        "    continuous_column_names = list(p_values_continuous.keys())\n",
        "    discrete_column_names = list(p_values_discrete.keys())\n",
        "\n",
        "    p_val = np.concatenate([list(p_values_continuous.values()), list(p_values_discrete.values())])\n",
        "    p_values_list.append(p_val)\n",
        "\n",
        "    workspace_dir = os.path.join(os.getcwd(), 'workspace')\n",
        "    if os.path.exists(workspace_dir):\n",
        "        shutil.rmtree(workspace_dir)\n",
        "\n",
        "result_df = pd.concat(metrics_list, axis=1)\n",
        "\n",
        "# Calculate the row-wise mean and standard deviation of the metrics\n",
        "result_df['Mean'] = result_df.mean(axis=1)\n",
        "result_df['Std'] = result_df.std(axis=1)\n",
        "result_df['Std'] = result_df['Std'].round(4)\n",
        "\n",
        "# Create DataFrame for p-values\n",
        "p_values_df = pd.DataFrame(p_values_list, columns=continuous_column_names + discrete_column_names)\n",
        "\n",
        "# Save result_df and p_values_df as CSV files\n",
        "result_df.to_csv(f\"/content/drive/MyDrive/Nips/{dataset}_{plugin_name}_result_df.csv\")\n",
        "p_values_df.to_csv(f\"/content/drive/MyDrive/Nips/{dataset}_{plugin_name}_p_values_df.csv\")\n",
        "\n",
        "avg_fit_time = np.mean(fit_times)\n",
        "avg_generate_time = np.mean(generate_times)\n",
        "std_fit_time = np.std(fit_times)\n",
        "std_generate_time = np.std(generate_times)\n",
        "\n",
        "print(f\"\\nAverage Fit Time: {avg_fit_time:.4f} seconds, Standard Deviation: {std_fit_time:.4f} seconds\")\n",
        "print(f\"Average Generate Time: {avg_generate_time:.4f} seconds, Standard Deviation: {std_generate_time:.4f} seconds\")\n"
      ],
      "metadata": {
        "id": "aE3-uY7ch7yp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result_df"
      ],
      "metadata": {
        "id": "oXoHD0A7jHJR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "p_values_df"
      ],
      "metadata": {
        "id": "430JnVP1jHDG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# AIDS"
      ],
      "metadata": {
        "id": "tVnRTBHHCt0d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset=\"aids\"\n",
        "\n",
        "metrics_list = []\n",
        "fit_times = []\n",
        "generate_times = []\n",
        "p_values_list = []\n",
        "\n",
        "for i in range(5):\n",
        "    df = pd.read_csv('/content/drive/MyDrive/Datasets/aids.csv')\n",
        "    df = df.drop('Unnamed: 0', axis=1)\n",
        "    df = df[df['duration'] != 0]\n",
        "\n",
        "    loader = SurvivalAnalysisDataLoader(\n",
        "    df,\n",
        "    target_column=\"event\",\n",
        "    time_to_event_column=\"duration\",\n",
        "    )\n",
        "\n",
        "\n",
        "    syn_model = Plugins().get(plugin_name)\n",
        "\n",
        "    # Measure the execution time of the fit function\n",
        "    start = timer()\n",
        "    syn_model.fit(loader)\n",
        "    fit_time = timer() - start\n",
        "    fit_times.append(fit_time)\n",
        "\n",
        "    random_state = i + 1\n",
        "    np.random.seed(random_state)\n",
        "\n",
        "    # Measure the execution time of the generate function\n",
        "    start = timer()\n",
        "    X_gen = syn_model.generate(count=len(df)).dataframe()\n",
        "    generate_time = timer() - start\n",
        "    generate_times.append(generate_time)\n",
        "\n",
        "    # Save X_gen as a CSV file\n",
        "    X_gen.to_csv(f\"/content/drive/MyDrive/Nips/{dataset}_{plugin_name}_iteration_{i+1}.csv\", index=False)\n",
        "\n",
        "    loader1 = SurvivalAnalysisDataLoader(df, target_column=\"event\", time_to_event_column=\"duration\")\n",
        "    loader2 = SurvivalAnalysisDataLoader(X_gen, target_column=\"event\", time_to_event_column=\"duration\")\n",
        "\n",
        "    met_df = Metrics.evaluate(X_gt=loader1, X_syn=loader2, task_type='survival_analysis', metrics={\n",
        "        'stats': ['jensenshannon_dist', 'chi_squared_test', 'feature_corr', 'inv_kl_divergence', 'ks_test',\n",
        "                 'max_mean_discrepancy', 'wasserstein_dist', 'prdc', 'alpha_precision', 'survival_km_distance'],\n",
        "        'performance': ['linear_model', 'mlp', 'xgb', 'feat_rank_distance']\n",
        "    }, use_cache=False, random_state=random_state)\n",
        "\n",
        "    met_df = met_df.iloc[:, 0]\n",
        "    metrics_list.append(met_df)\n",
        "\n",
        "    # Calculate p-values\n",
        "    p_values_continuous, p_values_discrete = compare_distributions(df, X_gen)\n",
        "    continuous_column_names = list(p_values_continuous.keys())\n",
        "    discrete_column_names = list(p_values_discrete.keys())\n",
        "\n",
        "    p_val = np.concatenate([list(p_values_continuous.values()), list(p_values_discrete.values())])\n",
        "    p_values_list.append(p_val)\n",
        "\n",
        "    workspace_dir = os.path.join(os.getcwd(), 'workspace')\n",
        "    if os.path.exists(workspace_dir):\n",
        "        shutil.rmtree(workspace_dir)\n",
        "\n",
        "result_df = pd.concat(metrics_list, axis=1)\n",
        "\n",
        "# Calculate the row-wise mean and standard deviation of the metrics\n",
        "result_df['Mean'] = result_df.mean(axis=1)\n",
        "result_df['Std'] = result_df.std(axis=1)\n",
        "result_df['Std'] = result_df['Std'].round(4)\n",
        "\n",
        "# Create DataFrame for p-values\n",
        "p_values_df = pd.DataFrame(p_values_list, columns=continuous_column_names + discrete_column_names)\n",
        "\n",
        "# Save result_df and p_values_df as CSV files\n",
        "result_df.to_csv(f\"/content/drive/MyDrive/Nips/{dataset}_{plugin_name}_result_df.csv\")\n",
        "p_values_df.to_csv(f\"/content/drive/MyDrive/Nips/{dataset}_{plugin_name}_p_values_df.csv\")\n",
        "\n",
        "avg_fit_time = np.mean(fit_times)\n",
        "avg_generate_time = np.mean(generate_times)\n",
        "std_fit_time = np.std(fit_times)\n",
        "std_generate_time = np.std(generate_times)\n",
        "\n",
        "print(f\"\\nAverage Fit Time: {avg_fit_time:.4f} seconds, Standard Deviation: {std_fit_time:.4f} seconds\")\n",
        "print(f\"Average Generate Time: {avg_generate_time:.4f} seconds, Standard Deviation: {std_generate_time:.4f} seconds\")\n"
      ],
      "metadata": {
        "id": "XLWVp7FlVHdD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result_df"
      ],
      "metadata": {
        "id": "dHBJijmUYIew"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "p_values_df"
      ],
      "metadata": {
        "id": "euNS1tINYKCm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Metabric"
      ],
      "metadata": {
        "id": "2jJPOKXocEu6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset=\"metabric\"\n",
        "\n",
        "metrics_list = []\n",
        "fit_times = []\n",
        "generate_times = []\n",
        "p_values_list = []\n",
        "\n",
        "for i in range(5):\n",
        "    df = datasets.metabric.read_df()\n",
        "    df = df[df['duration'] != 0]\n",
        "\n",
        "    loader = SurvivalAnalysisDataLoader(\n",
        "    df,\n",
        "    target_column=\"event\",\n",
        "    time_to_event_column=\"duration\",\n",
        "    )\n",
        "\n",
        "\n",
        "    syn_model = Plugins().get(plugin_name)\n",
        "\n",
        "    # Measure the execution time of the fit function\n",
        "    start = timer()\n",
        "    syn_model.fit(loader)\n",
        "    fit_time = timer() - start\n",
        "    fit_times.append(fit_time)\n",
        "\n",
        "    random_state = i + 1\n",
        "    np.random.seed(random_state)\n",
        "\n",
        "    # Measure the execution time of the generate function\n",
        "    start = timer()\n",
        "    X_gen = syn_model.generate(count=len(df)).dataframe()\n",
        "    generate_time = timer() - start\n",
        "    generate_times.append(generate_time)\n",
        "\n",
        "    # Save X_gen as a CSV file\n",
        "    X_gen.to_csv(f\"/content/drive/MyDrive/Nips/{dataset}_{plugin_name}_iteration_{i+1}.csv\", index=False)\n",
        "\n",
        "    loader1 = SurvivalAnalysisDataLoader(df, target_column=\"event\", time_to_event_column=\"duration\")\n",
        "    loader2 = SurvivalAnalysisDataLoader(X_gen, target_column=\"event\", time_to_event_column=\"duration\")\n",
        "\n",
        "    met_df = Metrics.evaluate(X_gt=loader1, X_syn=loader2, task_type='survival_analysis', metrics={\n",
        "        'stats': ['jensenshannon_dist', 'chi_squared_test', 'feature_corr', 'inv_kl_divergence', 'ks_test',\n",
        "                 'max_mean_discrepancy', 'wasserstein_dist', 'prdc', 'alpha_precision', 'survival_km_distance'],\n",
        "        'performance': ['linear_model', 'mlp', 'xgb', 'feat_rank_distance']\n",
        "    }, use_cache=False, random_state=random_state)\n",
        "\n",
        "    met_df = met_df.iloc[:, 0]\n",
        "    metrics_list.append(met_df)\n",
        "\n",
        "    # Calculate p-values\n",
        "    p_values_continuous, p_values_discrete = compare_distributions(df, X_gen)\n",
        "    continuous_column_names = list(p_values_continuous.keys())\n",
        "    discrete_column_names = list(p_values_discrete.keys())\n",
        "\n",
        "    p_val = np.concatenate([list(p_values_continuous.values()), list(p_values_discrete.values())])\n",
        "    p_values_list.append(p_val)\n",
        "\n",
        "    workspace_dir = os.path.join(os.getcwd(), 'workspace')\n",
        "    if os.path.exists(workspace_dir):\n",
        "        shutil.rmtree(workspace_dir)\n",
        "\n",
        "result_df = pd.concat(metrics_list, axis=1)\n",
        "\n",
        "# Calculate the row-wise mean and standard deviation of the metrics\n",
        "result_df['Mean'] = result_df.mean(axis=1)\n",
        "result_df['Std'] = result_df.std(axis=1)\n",
        "result_df['Std'] = result_df['Std'].round(4)\n",
        "\n",
        "# Create DataFrame for p-values\n",
        "p_values_df = pd.DataFrame(p_values_list, columns=continuous_column_names + discrete_column_names)\n",
        "\n",
        "# Save result_df and p_values_df as CSV files\n",
        "result_df.to_csv(f\"/content/drive/MyDrive/Nips/{dataset}_{plugin_name}_result_df.csv\")\n",
        "p_values_df.to_csv(f\"/content/drive/MyDrive/Nips/{dataset}_{plugin_name}_p_values_df.csv\")\n",
        "\n",
        "avg_fit_time = np.mean(fit_times)\n",
        "avg_generate_time = np.mean(generate_times)\n",
        "std_fit_time = np.std(fit_times)\n",
        "std_generate_time = np.std(generate_times)\n",
        "\n",
        "print(f\"\\nAverage Fit Time: {avg_fit_time:.4f} seconds, Standard Deviation: {std_fit_time:.4f} seconds\")\n",
        "print(f\"Average Generate Time: {avg_generate_time:.4f} seconds, Standard Deviation: {std_generate_time:.4f} seconds\")\n"
      ],
      "metadata": {
        "id": "40akL9o-2xuG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result_df"
      ],
      "metadata": {
        "id": "MCmPsJdX2xng"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "p_values_df"
      ],
      "metadata": {
        "id": "kWZ9aI4i2xf1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# GBSG"
      ],
      "metadata": {
        "id": "_Q90MorO3YqW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset=\"gbsg\"\n",
        "\n",
        "metrics_list = []\n",
        "fit_times = []\n",
        "generate_times = []\n",
        "p_values_list = []\n",
        "\n",
        "for i in range(5):\n",
        "    df = datasets.gbsg.read_df()\n",
        "    df = df[df['duration'] != 0]\n",
        "\n",
        "    loader = SurvivalAnalysisDataLoader(\n",
        "    df,\n",
        "    target_column=\"event\",\n",
        "    time_to_event_column=\"duration\",\n",
        "    )\n",
        "\n",
        "\n",
        "    syn_model = Plugins().get(plugin_name)\n",
        "\n",
        "    # Measure the execution time of the fit function\n",
        "    start = timer()\n",
        "    syn_model.fit(loader)\n",
        "    fit_time = timer() - start\n",
        "    fit_times.append(fit_time)\n",
        "\n",
        "    random_state = i + 1\n",
        "    np.random.seed(random_state)\n",
        "\n",
        "    # Measure the execution time of the generate function\n",
        "    start = timer()\n",
        "    X_gen = syn_model.generate(count=len(df)).dataframe()\n",
        "    generate_time = timer() - start\n",
        "    generate_times.append(generate_time)\n",
        "\n",
        "    # Save X_gen as a CSV file\n",
        "    X_gen.to_csv(f\"/content/drive/MyDrive/Nips/{dataset}_{plugin_name}_iteration_{i+1}.csv\", index=False)\n",
        "\n",
        "    loader1 = SurvivalAnalysisDataLoader(df, target_column=\"event\", time_to_event_column=\"duration\")\n",
        "    loader2 = SurvivalAnalysisDataLoader(X_gen, target_column=\"event\", time_to_event_column=\"duration\")\n",
        "\n",
        "    met_df = Metrics.evaluate(X_gt=loader1, X_syn=loader2, task_type='survival_analysis', metrics={\n",
        "        'stats': ['jensenshannon_dist', 'chi_squared_test', 'feature_corr', 'inv_kl_divergence', 'ks_test',\n",
        "                 'max_mean_discrepancy', 'wasserstein_dist', 'prdc', 'alpha_precision', 'survival_km_distance'],\n",
        "        'performance': ['linear_model', 'mlp', 'xgb', 'feat_rank_distance']\n",
        "    }, use_cache=False, random_state=random_state)\n",
        "\n",
        "    met_df = met_df.iloc[:, 0]\n",
        "    metrics_list.append(met_df)\n",
        "\n",
        "    # Calculate p-values\n",
        "    p_values_continuous, p_values_discrete = compare_distributions(df, X_gen)\n",
        "    continuous_column_names = list(p_values_continuous.keys())\n",
        "    discrete_column_names = list(p_values_discrete.keys())\n",
        "\n",
        "    p_val = np.concatenate([list(p_values_continuous.values()), list(p_values_discrete.values())])\n",
        "    p_values_list.append(p_val)\n",
        "\n",
        "    workspace_dir = os.path.join(os.getcwd(), 'workspace')\n",
        "    if os.path.exists(workspace_dir):\n",
        "        shutil.rmtree(workspace_dir)\n",
        "\n",
        "result_df = pd.concat(metrics_list, axis=1)\n",
        "\n",
        "# Calculate the row-wise mean and standard deviation of the metrics\n",
        "result_df['Mean'] = result_df.mean(axis=1)\n",
        "result_df['Std'] = result_df.std(axis=1)\n",
        "result_df['Std'] = result_df['Std'].round(4)\n",
        "\n",
        "# Create DataFrame for p-values\n",
        "p_values_df = pd.DataFrame(p_values_list, columns=continuous_column_names + discrete_column_names)\n",
        "\n",
        "# Save result_df and p_values_df as CSV files\n",
        "result_df.to_csv(f\"/content/drive/MyDrive/Nips/{dataset}_{plugin_name}_result_df.csv\")\n",
        "p_values_df.to_csv(f\"/content/drive/MyDrive/Nips/{dataset}_{plugin_name}_p_values_df.csv\")\n",
        "\n",
        "avg_fit_time = np.mean(fit_times)\n",
        "avg_generate_time = np.mean(generate_times)\n",
        "std_fit_time = np.std(fit_times)\n",
        "std_generate_time = np.std(generate_times)\n",
        "\n",
        "print(f\"\\nAverage Fit Time: {avg_fit_time:.4f} seconds, Standard Deviation: {std_fit_time:.4f} seconds\")\n",
        "print(f\"Average Generate Time: {avg_generate_time:.4f} seconds, Standard Deviation: {std_generate_time:.4f} seconds\")\n"
      ],
      "metadata": {
        "id": "J_vUdi722-V3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result_df"
      ],
      "metadata": {
        "id": "CmUmr6x-294_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "p_values_df"
      ],
      "metadata": {
        "id": "aYZaCxoW3gN4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SUPPORT"
      ],
      "metadata": {
        "id": "Rf0dJwdN3iHi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset=\"support\"\n",
        "\n",
        "metrics_list = []\n",
        "fit_times = []\n",
        "generate_times = []\n",
        "p_values_list = []\n",
        "\n",
        "for i in range(5):\n",
        "    df = datasets.support.read_df()\n",
        "    df = df[df['duration'] != 0]\n",
        "\n",
        "    loader = SurvivalAnalysisDataLoader(\n",
        "    df,\n",
        "    target_column=\"event\",\n",
        "    time_to_event_column=\"duration\",\n",
        "    )\n",
        "\n",
        "\n",
        "    syn_model = Plugins().get(plugin_name)\n",
        "\n",
        "    # Measure the execution time of the fit function\n",
        "    start = timer()\n",
        "    syn_model.fit(loader)\n",
        "    fit_time = timer() - start\n",
        "    fit_times.append(fit_time)\n",
        "\n",
        "    random_state = i + 1\n",
        "    np.random.seed(random_state)\n",
        "\n",
        "    # Measure the execution time of the generate function\n",
        "    start = timer()\n",
        "    X_gen = syn_model.generate(count=len(df)).dataframe()\n",
        "    generate_time = timer() - start\n",
        "    generate_times.append(generate_time)\n",
        "\n",
        "    # Save X_gen as a CSV file\n",
        "    X_gen.to_csv(f\"/content/drive/MyDrive/Nips/{dataset}_{plugin_name}_iteration_{i+1}.csv\", index=False)\n",
        "\n",
        "    loader1 = SurvivalAnalysisDataLoader(df, target_column=\"event\", time_to_event_column=\"duration\")\n",
        "    loader2 = SurvivalAnalysisDataLoader(X_gen, target_column=\"event\", time_to_event_column=\"duration\")\n",
        "\n",
        "    met_df = Metrics.evaluate(X_gt=loader1, X_syn=loader2, task_type='survival_analysis', metrics={\n",
        "        'stats': ['jensenshannon_dist', 'chi_squared_test', 'feature_corr', 'inv_kl_divergence', 'ks_test',\n",
        "                 'max_mean_discrepancy', 'wasserstein_dist', 'prdc', 'alpha_precision', 'survival_km_distance'],\n",
        "        'performance': ['linear_model', 'mlp', 'xgb', 'feat_rank_distance']\n",
        "    }, use_cache=False, random_state=random_state)\n",
        "\n",
        "    met_df = met_df.iloc[:, 0]\n",
        "    metrics_list.append(met_df)\n",
        "\n",
        "    # Calculate p-values\n",
        "    p_values_continuous, p_values_discrete = compare_distributions(df, X_gen)\n",
        "    continuous_column_names = list(p_values_continuous.keys())\n",
        "    discrete_column_names = list(p_values_discrete.keys())\n",
        "\n",
        "    p_val = np.concatenate([list(p_values_continuous.values()), list(p_values_discrete.values())])\n",
        "    p_values_list.append(p_val)\n",
        "\n",
        "    workspace_dir = os.path.join(os.getcwd(), 'workspace')\n",
        "    if os.path.exists(workspace_dir):\n",
        "        shutil.rmtree(workspace_dir)\n",
        "\n",
        "result_df = pd.concat(metrics_list, axis=1)\n",
        "\n",
        "# Calculate the row-wise mean and standard deviation of the metrics\n",
        "result_df['Mean'] = result_df.mean(axis=1)\n",
        "result_df['Std'] = result_df.std(axis=1)\n",
        "result_df['Std'] = result_df['Std'].round(4)\n",
        "\n",
        "# Create DataFrame for p-values\n",
        "p_values_df = pd.DataFrame(p_values_list, columns=continuous_column_names + discrete_column_names)\n",
        "\n",
        "# Save result_df and p_values_df as CSV files\n",
        "result_df.to_csv(f\"/content/drive/MyDrive/Nips/{dataset}_{plugin_name}_result_df.csv\")\n",
        "p_values_df.to_csv(f\"/content/drive/MyDrive/Nips/{dataset}_{plugin_name}_p_values_df.csv\")\n",
        "\n",
        "avg_fit_time = np.mean(fit_times)\n",
        "avg_generate_time = np.mean(generate_times)\n",
        "std_fit_time = np.std(fit_times)\n",
        "std_generate_time = np.std(generate_times)\n",
        "\n",
        "print(f\"\\nAverage Fit Time: {avg_fit_time:.4f} seconds, Standard Deviation: {std_fit_time:.4f} seconds\")\n",
        "print(f\"Average Generate Time: {avg_generate_time:.4f} seconds, Standard Deviation: {std_generate_time:.4f} seconds\")\n"
      ],
      "metadata": {
        "id": "pzp6chZi3lbt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result_df"
      ],
      "metadata": {
        "id": "CBW3qLE73lYP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "p_values_df"
      ],
      "metadata": {
        "id": "i-v0i0Yu3lUw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# FLCHAIN"
      ],
      "metadata": {
        "id": "pvMBYUJV50Vh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset=\"flchain\"\n",
        "\n",
        "metrics_list = []\n",
        "fit_times = []\n",
        "generate_times = []\n",
        "p_values_list = []\n",
        "\n",
        "for i in range(5):\n",
        "    df=pd.read_csv('/content/drive/MyDrive/Datasets/flchain.csv')\n",
        "    df = df.drop('Unnamed: 0', axis=1)\n",
        "    df = df[df['duration'] != 0]\n",
        "    df=df.dropna()\n",
        "\n",
        "    time = df['duration'].to_list()\n",
        "    event = df['event'].to_list()\n",
        "\n",
        "    time_event_encoded = sinusoidal_embedding(time, event, 4)\n",
        "    X = df.drop(['duration', 'event'], axis=1)\n",
        "    y = time_event_encoded\n",
        "\n",
        "    syn_model = Plugins().get(plugin_name)\n",
        "\n",
        "    # Measure the execution time of the fit function\n",
        "    start = timer()\n",
        "    syn_model.fit(X, cond=y)\n",
        "    fit_time = timer() - start\n",
        "    fit_times.append(fit_time)\n",
        "\n",
        "    survival_df=df\n",
        "    event_0_data = survival_df[survival_df['event'] == 0]['duration']\n",
        "    event_1_data = survival_df[survival_df['event'] == 1]['duration']\n",
        "\n",
        "    random_state = i + 1\n",
        "    np.random.seed(random_state)\n",
        "\n",
        "    sample_size_0 = len(event_0_data)\n",
        "    sample_size_1= len(event_1_data)\n",
        "    sample_event_0 = np.random.choice(event_0_data, size=sample_size_0)\n",
        "    sample_event_1 = np.random.choice(event_1_data, size=sample_size_1)\n",
        "\n",
        "    z=np.concatenate([sample_event_0,sample_event_1])\n",
        "    x=np.zeros(len(sample_event_0))\n",
        "    y=np.ones(len(sample_event_1))\n",
        "    p=np.concatenate([x,y])\n",
        "\n",
        "    time_event_gen_encoded=sinusoidal_embedding(z,p,4)\n",
        "\n",
        "    # Measure the execution time of the generate function\n",
        "    start = timer()\n",
        "    X_gen = syn_model.generate(count=len(df), cond=np.array(time_event_gen_encoded)).dataframe()\n",
        "    generate_time = timer() - start\n",
        "    generate_times.append(generate_time)\n",
        "\n",
        "    X_gen['duration'] = z\n",
        "    X_gen['event'] = p\n",
        "    X_gen = X_gen.sample(frac=1).reset_index(drop=True)\n",
        "\n",
        "    # Save X_gen as a CSV file\n",
        "    X_gen.to_csv(f\"/content/drive/MyDrive/Nips/{dataset}_{plugin_name}_iteration_{i+1}.csv\", index=False)\n",
        "\n",
        "    loader1 = SurvivalAnalysisDataLoader(df, target_column=\"event\", time_to_event_column=\"duration\")\n",
        "    loader2 = SurvivalAnalysisDataLoader(X_gen, target_column=\"event\", time_to_event_column=\"duration\")\n",
        "\n",
        "    met_df = Metrics.evaluate(X_gt=loader1, X_syn=loader2, task_type='survival_analysis', metrics={\n",
        "        'stats': ['jensenshannon_dist', 'chi_squared_test', 'feature_corr', 'inv_kl_divergence', 'ks_test',\n",
        "                 'max_mean_discrepancy', 'wasserstein_dist', 'prdc', 'alpha_precision', 'survival_km_distance'],\n",
        "        'performance': ['linear_model', 'mlp', 'xgb', 'feat_rank_distance']\n",
        "    }, use_cache=False, random_state=random_state)\n",
        "\n",
        "    met_df = met_df.iloc[:, 0]\n",
        "    metrics_list.append(met_df)\n",
        "\n",
        "    # Calculate p-values\n",
        "    p_values_continuous, p_values_discrete = compare_distributions(df, X_gen)\n",
        "    continuous_column_names = list(p_values_continuous.keys())\n",
        "    discrete_column_names = list(p_values_discrete.keys())\n",
        "\n",
        "    p_val = np.concatenate([list(p_values_continuous.values()), list(p_values_discrete.values())])\n",
        "    p_values_list.append(p_val)\n",
        "\n",
        "    workspace_dir = os.path.join(os.getcwd(), 'workspace')\n",
        "    if os.path.exists(workspace_dir):\n",
        "        shutil.rmtree(workspace_dir)\n",
        "\n",
        "result_df = pd.concat(metrics_list, axis=1)\n",
        "\n",
        "# Calculate the row-wise mean and standard deviation of the metrics\n",
        "result_df['Mean'] = result_df.mean(axis=1)\n",
        "result_df['Std'] = result_df.std(axis=1)\n",
        "result_df['Std'] = result_df['Std'].round(4)\n",
        "\n",
        "# Create DataFrame for p-values\n",
        "p_values_df = pd.DataFrame(p_values_list, columns=continuous_column_names + discrete_column_names)\n",
        "\n",
        "# Save result_df and p_values_df as CSV files\n",
        "result_df.to_csv(f\"/content/drive/MyDrive/Nips/{dataset}_{plugin_name}_result_df.csv\")\n",
        "p_values_df.to_csv(f\"/content/drive/MyDrive/Nips/{dataset}_{plugin_name}_p_values_df.csv\")\n",
        "\n",
        "avg_fit_time = np.mean(fit_times)\n",
        "avg_generate_time = np.mean(generate_times)\n",
        "std_fit_time = np.std(fit_times)\n",
        "std_generate_time = np.std(generate_times)\n",
        "\n",
        "print(f\"\\nAverage Fit Time: {avg_fit_time:.4f} seconds, Standard Deviation: {std_fit_time:.4f} seconds\")\n",
        "print(f\"Average Generate Time: {avg_generate_time:.4f} seconds, Standard Deviation: {std_generate_time:.4f} seconds\")\n"
      ],
      "metadata": {
        "id": "2C0z5zCb54mT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result_df"
      ],
      "metadata": {
        "id": "nYYpzISjlsgv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "p_values_df"
      ],
      "metadata": {
        "id": "xiul05x_54LD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df=pd.read_csv('/content/drive/MyDrive/Datasets/flchain.csv')\n",
        "df = df.drop('Unnamed: 0', axis=1)\n",
        "df = df[df['duration'] != 0]\n",
        "df=df.dropna()"
      ],
      "metadata": {
        "id": "hTDe6qNMmi_O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "EddUEPHCmljf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QvHyE_sPmmEz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}